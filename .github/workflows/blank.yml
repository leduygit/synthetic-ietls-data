name: IELTS Essay Generator Pipeline

on:
  push:
    paths:
      - "readme.md" # Trigger only when README.md changes

jobs:
  generate:
    runs-on: ubuntu-latest
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      KAGGLE_JSON: ${{ secrets.KAGGLE_JSON }}
    steps:
      - uses: actions/checkout@v3

      - name: Verify env
        run: |
          if [ -z "$OPENAI_API_KEY" ]; then
            echo "âŒ OPENAI_API_KEY is not set!"
            exit 1
          else
            echo "âœ… OPENAI_API_KEY is available"
          fi

  pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt kaggle

      - name: Update CA certificates
        run: sudo apt-get update && sudo apt-get install -y ca-certificates

      - name: Debug OpenAI API with curl
        run: |
          curl -v https://api.openai.com/v1/models \
            -H "Authorization: Bearer $OPENAI_API_KEY"
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      - name: Check README value
        id: readme
        run: |
          value=$(tail -n 1 readme.md)
          echo "lastval=$value" >> $GITHUB_ENV
          if [ "$value" -eq 5 ]; then
            echo "Value is 5, stopping workflow."
            exit 0
          fi

      - name: Run with IPv4 only
        run: |
          python - <<'EOF'
          import os, socket
          import requests.packages.urllib3.util.connection as urllib3_cn

          def allowed_gai_family():
              return socket.AF_INET
          urllib3_cn.allowed_gai_family = allowed_gai_family

          from openai import OpenAI
          client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

          try:
              resp = client.chat.completions.create(
                  model="gpt-4o-mini",
                  messages=[{"role": "user", "content": "Hello from IPv4-only run"}],
                  max_tokens=10
              )
              print("âœ… Success:", resp.choices[0].message.content)
          except Exception as e:
              print("âŒ Failed:", e)
          EOF
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      - name: Run essay generator
        run: |
          python gen-data.py 5 --num-essays 1
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      # ðŸ”½ Configure Kaggle API
      - name: Configure Kaggle API
        run: |
          mkdir -p ~/.kaggle
          echo "{\"username\":\"$KAGGLE_USERNAME\",\"key\":\"$KAGGLE_KEY\"}" > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}

      # ðŸ”½ Pull dataset metadata
      - name: Pull Kaggle dataset metadata
        run: kaggle datasets metadata thanhnghia123/mielband-ielts-data-train -p ./dataset_meta


      - name: Patch dataset-metadata.json with ID
        run: |
          cat ./dataset_meta/dataset-metadata.json | jq -r '.' | jq '.id = "thanhnghia123/mielband-ielts-data-train"' > ./dataset_meta/tmp.json
          mv ./dataset_meta/tmp.json ./dataset_meta/dataset-metadata.json
          echo "âœ… Patched dataset-metadata.json with ID"


      # ðŸ”½ Add generated CSV & push dataset
      - name: Upload generated CSV to Kaggle dataset (inside training/)
        run: |
          latest_csv=$(ls -t band_*.csv | head -n 1)
          echo "Found CSV: $latest_csv"

          mkdir -p ./dataset_meta/training
          cp "$latest_csv" ./dataset_meta/training/

          kaggle datasets version -p ./dataset_meta -m "Update dataset with $latest_csv" -r zip

      # ðŸ”½ Pull notebook metadata
      - name: Pull Kaggle notebook metadata
        run: kaggle kernels pull blueinthe/train --metadata -p ./notebook_meta

      # ðŸ”½ Ensure notebook metadata has correct ID and code_file
      - name: Patch kernel-metadata.json with ID
        run: |
          jq '.id = "blueinthe/train" | .code_file = "train.ipynb"' ./notebook_meta/kernel-metadata.json > ./notebook_meta/tmp.json
          mv ./notebook_meta/tmp.json ./notebook_meta/kernel-metadata.json
          echo "âœ… Patched kernel-metadata.json with correct ID and code_file"

      # ðŸ”½ Push & run notebook
      - name: Push & Run Kaggle Notebook
        run: |
          cp train.ipynb ./notebook_meta/
          kaggle kernels push -p ./notebook_meta
          echo "Starting notebook run..."
          kaggle kernels run blueinthe/train
